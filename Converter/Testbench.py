# -*- coding: utf-8 -*-
"""TESTE_TODOS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ypK6kVqWjMlnOsRhOtz557ph2J1RR5U0
"""

from google.colab import drive

drive.mount('/content/gdrive', force_remount=True)
root_path = 'gdrive/My Drive/SDA/'

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
import torchvision
import torchvision.transforms as transforms
import numpy as np 
import matplotlib.pyplot as plt
import sys

class Perceptron(nn.Module):
	def __init__(self):
		super(Perceptron, self).__init__()
		self.neuron = nn.Linear(32*32,10)
		self.activation_function = nn.ReLU()

	def forward(self, x):
		print('Perceptron: ', self.neuron(x.view(-1, 32*32)))
		x = x.view(-1, 32*32)
		x = self.activation_function(self.neuron(x))
		return x


class MLP(nn.Module):
	def __init__(self):
		super(MLP, self).__init__()
		self.layer_1 = nn.Linear(32*32,20)
		self.layer_2 = nn.Linear(20,10)
		self.activation_function = nn.ReLU()
		self.drop = nn.Dropout(0.5)

	def forward(self, x):
		print('MLP - 1 Camada: ', self.layer_1(x.view(-1, 32*32)))
		print('MLP - 2 Camada: ', self.layer_2(self.layer_1(x.view(-1, 32*32))))
		x = x.view(-1, 32*32)
		x = self.drop(self.activation_function(self.layer_1(x)))
	
		x = self.activation_function(self.layer_2(x))

		return x

transform = transforms.Compose([transforms.Grayscale(num_output_channels = 1), transforms.ToTensor()])

dataset_train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)# / 255
dataset_test = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)# / 255

dataset_train = DataLoader(dataset=dataset_train, shuffle=True)
dataset_test = DataLoader(dataset=dataset_test, shuffle=False)

net = MLP()
net_2 = Perceptron()
# if sys.argv[1] == '0':

# 	optimizer = torch.optim.SGD(net.parameters(), lr = 0.01, momentum = 0.1)
# 	loss_function = torch.nn.CrossEntropyLoss()
# 	accuracy_vector = []
# 	loss_vector = []

# 	for epoch in range(20):
		
# 		acc = 0	
# 		for img, label in dataset_train:
# 			net.train()
# 			optimizer.zero_grad()
# 			out = net(img)
# 			loss = loss_function(out, label)
# 			loss_vector.append(loss)
# 			loss.backward()
# 			optimizer.step()

# 			net.eval()
# 			Out = net(img)
# 			_, pred = torch.max(out.data, 1)
# 			acc += (pred == label).sum().item()

# 		accuracy = 100 * acc / len(dataset_train.dataset)
# 		accuracy_vector.append(accuracy)
# 		print('Epoch: {}\t Accuracy: {}/{} [{}%]'.format(epoch, acc, len(dataset_train.dataset), accuracy))

# 	torch.save(net.state_dict(), '/home/lindino/Documentos/weights_mlp.pt')
# 	plt.plot(loss_vector)
# 	plt.show()

# 	plt.plot(accuracy_vector)
# 	plt.show()

# elif sys.argv[1] == '1':

net.load_state_dict(torch.load(root_path + 'weights_mlp.pt'))
net_2.load_state_dict(torch.load(root_path + 'weights_perceptron.pt'))

net.eval()
net_2.eval()

# 	correct = 0
# 	for img, label in dataset_test:
# 		out = net(img)
# 		_, pred = torch.max(out.data, 1)
# 		correct += (pred == label).sum().item()

# 	accuracy = 100 * correct / len(dataset_test.dataset)
# 	print('\tTest \t Accuracy: {}/{} [{}%]'.format(correct, len(dataset_test.dataset), accuracy))

fileW = open(root_path + 'STRINGweight2010MLP.txt', 'a')
fileB = open(root_path + 'STRINGbias2010MLP.txt', 'a')

for layer in net.state_dict():
 fileW.write(layer + '\n')
 for tensor in net.state_dict()[layer]:
    if (layer == 'layer_1.weight') or (layer == 'layer_2.weight'):
       for value in tensor.numpy():
         fileW.write(str('%.24f' % value) + '\n')
    else:
      fileB.write(str(tensor.numpy()) + '\n')

fileW.close()
fileB.close()

# for layer in net.state_dict():
#   print(layer)
#   for tensor in net.state_dict()[layer]:
#     print(tensor)

for img, label in dataset_test:
 out = net(img)
 out_2 = net_2(img)
 break

def fixed_to_float( number, bits = 32):
  return number / (1 << bits)

resultsMLP = [18048198279, 24783332659, 26613489311, 15537256965, 16478068542, 33852026488, 24750147643, 6062045939, 9671251258, 16777301962]
resultsP = [-2488496935, -2669086587, -27045869268, -2896448943, -1621581215, -3130652027, -10532094283, -2816572688, -2787270573, -23471591072]

for x in resultsMLP:
	print(fixed_to_float(x))

print('\n')
for y in resultsP:
	print(fixed_to_float(y))

